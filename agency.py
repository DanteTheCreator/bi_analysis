from autogen import UserProxyAgent, ConversableAgent
import tempfile
from autogen.coding import LocalCommandLineCodeExecutor


class Agency:
    def __init__(self,):
        self.llm_config = {
            "config_list": [
                {
                    "model": "QuantFactory/Meta-Llama-3-8B-Instruct-GGUF",
                    "base_url": "http://10.80.17.130:1234/v1",
                    "api_key": "lm-studio",
                },

            ],
            "cache_seed": None,  # Disable caching.
            "temperature": 0
        }

        self.user_proxy = UserProxyAgent(
            name="user_proxy",
            llm_config=False,
            code_execution_config=False,
            human_input_mode="NEVER",
        )
        # Create a temporary directory to store the code files.
        temp_dir = tempfile.TemporaryDirectory()

        # Create a local command line code executor.
        self.executor = LocalCommandLineCodeExecutor(
            timeout=10,  # Timeout for each code execution in seconds.
            # Use the temporary directory to store the code files.
            work_dir=temp_dir.name,
        )
        self.code_executor_agent = ConversableAgent(
            "code_executor_agent",
            llm_config=False,  # Turn off LLM for this agent.
            # Use the local command line code executor.
            code_execution_config={"executor": self.executor},
            # Always take human input for this agent for safety.
            human_input_mode="ALWAYS",
        )
        
        self.decomposer = ConversableAgent(
            name="Decomposer",
            human_input_mode='NEVER',
            system_message="""
            Given a user's description of the data they need, decompose the task and determine how to query it from database.
            a. Provide detailed instructions for the Query Builder.
            b. Provide a description of the expected data that will be generated by the SQL query, including the column names and data types.
            
            Evaluate the decomposition to ensure it accurately captures the requirements and provides an efficient approach to retrieve and analyze the data.
            Deliver the instructions to the Query Builder.
            Avoid providing Specific data retrieval queries needed to extract the data from the database, avoid writing SQL! Provide the instructions for generating such queries (SQL)
            According to this schema:
            public.test_transactions_master_aggregated
                            (
                                column_name                 data_type
                                0           transaction_id                    bigint
                                1              customer_id                   integer
                                2         transaction_date  timestamp with time zone
                                3                trans_val          double precision
                                4                  balance          double precision
                                5         reference_object                   integer
                                6  reference_object_bigint                    bigint
                                7                   status         character varying ( status can be one of these:
                                0         bbet
                                1          Bet
                                2        Bonus
                                3      Deposit
                                4          Fee
                                5  Withdrawals
                                6          Won
                                7         wwon));
    
    """,
            llm_config=self.llm_config,
        )

        self.query_builder = ConversableAgent(
            name="query_builder",
            description="builds SQL query",
            human_input_mode='NEVER',
            system_message="""
           You will receive a task and focus on Database Operations. There will be a detailed plan for building a PostgreSQL query. Given a detailed description of the required data fields, tables, and conditions extracted by the Decomposer, construct a SQL query that accurately retrieves this data from the database. Include:
 
Selection of relevant fields.
Identification of necessary tables and how they join, if applicable.
Specification of conditions and filters to apply to the data.
Any sorting or grouping operations that are required.
Generate clean and efficient SQL code that is ready to be executed to fetch the needed data from this table:
public.test_transactions_master_aggregated
 
column_name data_type
transaction_id  bigint
customer_id integer
transaction_date    timestamp with time zone
trans_val   double precision
balance double precision
reference_object    integer
reference_object_bigint bigint
status  character varying
Possible values for status:
 
bbet
Bet
Bonus
Deposit
Fee
Withdrawals
Won
wwon
Provide a single clean SQL query in this format:
 
sql
Copy code
HERE
Please write the SQL between sql HERE . Avoid giving extra suggestions. Provide pure SQL like in the examples. Ensure proper error handling by avoiding the use of aliases in the WHERE clause or any part of the query before they are fully defined in the SELECT clause.
 
Examples:
 
sql
Copy code
SELECT * FROM public.test_transactions_master_aggregated;
Explanation: This query retrieves all columns and all rows from the test_transactions_master_aggregated table. It's the simplest form of a SELECT statement and is used to display the entire content of a table.
 
sql
Copy code
SELECT transaction_id, customer_id, trans_val, balance
FROM public.test_transactions_master_aggregated
WHERE balance > 1000.0;
Explanation: This query selects specific columns (transaction_id, customer_id, trans_val, balance) from the table, but only where the balance is greater than 1000.0. This is useful for filtering records based on specific criteria.
 
sql
Copy code
SELECT customer_id, COUNT(*) AS number_of_transactions, SUM(trans_val) AS total_spent
FROM public.test_transactions_master_aggregated
GROUP BY customer_id
HAVING SUM(trans_val) > 5000;
Explanation: This query groups the data by customer_id and calculates two things: the total number of transactions and the total transaction value (trans_val) per customer. The HAVING clause further filters these groups to include only those customers whose total spent is greater than 5000. This is useful for summarizing data by a certain attribute.
 
sql
Copy code
SELECT transaction_id, transaction_date, trans_val
FROM public.test_transactions_master_aggregated
WHERE transaction_date BETWEEN '2024-01-01' AND '2024-12-31'
ORDER BY transaction_date DESC;
Explanation: This query fetches the transaction ID, date, and value of transactions that occurred within the year 2024. The results are sorted by the transaction_date in descending order, so the most recent transactions appear first. This type of query is useful for analyzing data within a specific time frame.
 
sql
Copy code
SELECT transaction_id, trans_val, customer_id
FROM public.test_transactions_master_aggregated
WHERE customer_id IN (
    SELECT customer_id
    FROM public.test_transactions_master_aggregated
    WHERE trans_val > 1000
    GROUP BY customer_id
    HAVING COUNT(transaction_id) > 5
)
ORDER BY trans_val DESC;
Explanation: This query selects transactions from customers who have more than five transactions exceeding a value of 1000. It uses a subquery in the WHERE clause to first identify those customer_ids meeting the criteria, and then fetches data from the main table for those customers. This is a more complex SQL operation that involves nested querying, useful for filtering data based on aggregate properties.
 
sql
Copy code
SELECT transaction_id, transaction_date, customer_id, trans_val,
    SUM(trans_val) OVER (PARTITION BY customer_id ORDER BY transaction_date) AS running_total
FROM public.test_transactions_master_aggregated
ORDER BY customer_id, transaction_date;
Explanation: This query calculates a running total of transaction values for each customer, ordered by the transaction date. It uses a window function (SUM() OVER) which is a powerful tool for performing calculations across sets of rows that are related to the current row.
 
Final Note:
Ensure that the SQL query is clean and efficient, accurately reflecting the userâ€™s requirements. Avoid using aliases in the WHERE clause or any conditions before they are fully defined in the SELECT clause. Handle errors by ensuring that all column references are accurate and appropriately placed.
 
 
            """,
            llm_config=self.llm_config,
        )

        self.script_builder = ConversableAgent(
            name="script_builder",
            description="builds python script",
            llm_config=self.llm_config,
            human_input_mode="NEVER",
            code_execution_config=False,
            system_message=""" 
            You are an expert data scientist who codes in Python. Upon user request, write python script to transform df or create visualizations. 
            Assume that variable 'df' will be passed in automatically. Avoid creating or renaming variables, start with 'df', transform it according to the prompt.
                           
            Note: Data will already be a pandas DataFrame, avoid creating sample data in the script. Avoid leaving code half-done, avoid expecting me to fill in the code. Provide full
            code that works, only assume you have df from the start. Modify df and don't change it's name. 
            
            ALWAYS provide python like this ```python ```;
            After imports always define global df. 
            
            NEVER return df, avoid returning anything, NEVER use print, Instead you will apply it to df.
            Give back clear Python and instead of a return statement, include df = NEEDED DATA. If user is asking to return or show them something, just apply it to df.
            End code with:
            df = 'user's desired data' (preferably in a pndas dataframe)
            
            Example:
            User asked:
            'show me df head'
            Expected output:
            ```python
            import pandas as pd
            global df
            df = df.head()
            ```
            
            If user asks for visualization tasks using matplotlib, take care of creating Figs. Avoid just saying plt.show(). Construct Figure and assign the value to df.
            Make the Figure using dark theme
            Example:
            User Asked:
            'show me a pie chart'
            Expected output:
             ```python
            df['transaction_count'] = df['transaction_count'].astype(int)

            # Select the top 5 customers with the highest transaction counts
            top_customers = df.nlargest(5, 'transaction_count')

            # Create the pie chart
            fig, ax = plt.subplots(figsize=(10, 8))
            top_customers.plot.pie(ax=ax, y='transaction_count', labels=top_customers['customer_id'], autopct='%1.1f%%')
            ax.set_ylabel('')  # Optional: to remove the y-axis label which is redundant in a pie chart
            ax.set_title('Top 5 Customers by Transaction Count')

            df = fig
            ```
        """,

        )
